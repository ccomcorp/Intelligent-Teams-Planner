# RAG Service - Hybrid Multi-Source Implementation Plan

**Epic:** Epic 6 - Data Management and Analytics  
**Stories:** 6.1 (Advanced Document Processing Pipeline), 6.2 (Vector Database Semantic Search)  
**Status:** ğŸŸ¡ IN PROGRESS  
**Approach:** Hybrid Multi-Source Document Ingestion

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCUMENT SOURCES                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. OpenWebUI Workspace/Knowledge                               â”‚
â”‚     â””â”€> Direct HTTP Upload â†’ /api/upload                        â”‚
â”‚                                                                  â”‚
â”‚  2. Teams Chat Attachments                                      â”‚
â”‚     â””â”€> teams-bot receives â†’ forwards to /api/upload            â”‚
â”‚                                                                  â”‚
â”‚  3. Planner Task Attachments                                    â”‚
â”‚     â””â”€> Polling service â†’ Graph API â†’ /api/upload               â”‚
â”‚                                                                  â”‚
â”‚  4. SharePoint/OneDrive (Future)                                â”‚
â”‚     â””â”€> Webhook/Polling â†’ Graph API â†’ /api/upload               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   RAG Service (Port 7120)     â”‚
         â”‚                               â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚  Ingestion Layer        â”‚  â”‚
         â”‚  â”‚  - OpenWebUI Handler    â”‚  â”‚
         â”‚  â”‚  - Teams Handler        â”‚  â”‚
         â”‚  â”‚  - Planner Handler      â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚             â”‚                  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚  Processing Layer       â”‚  â”‚
         â”‚  â”‚  - Document Processor   â”‚  â”‚
         â”‚  â”‚  - Chunker              â”‚  â”‚
         â”‚  â”‚  - Embeddings Generator â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚             â”‚                  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚  Storage Layer          â”‚  â”‚
         â”‚  â”‚  - Vector Store         â”‚  â”‚
         â”‚  â”‚  - Metadata Store       â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚             â”‚                  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚  Query Layer            â”‚  â”‚
         â”‚  â”‚  - Semantic Search      â”‚  â”‚
         â”‚  â”‚  - RAG Engine           â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   PostgreSQL + pgvector       â”‚
         â”‚   (Unified Vector Storage)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Query Interfaces            â”‚
         â”‚   - OpenWebUI Chat            â”‚
         â”‚   - Teams Bot                 â”‚
         â”‚   - Direct API                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Phases

### **Phase 1: Core Infrastructure (Week 1 - Days 1-2)**

**Goal:** Setup service foundation and database schema

**Tasks:**
- [x] Create directory structure
- [x] Setup requirements.txt with all dependencies
- [x] Create environment configuration
- [x] Create base document handler abstract class
- [ ] Setup virtual environment with uv
- [ ] Create database schema for documents and chunks
- [ ] Implement health check endpoint
- [ ] Create basic FastAPI application structure

**Deliverables:**
- âœ… Service skeleton with proper structure
- âœ… Database schema ready
- âœ… Health endpoint functional

---

### **Phase 2: Document Processing Pipeline (Week 1 - Days 3-5)**

**Goal:** Implement core document processing capabilities

**Tasks:**
- [x] Implement DocumentProcessor class âœ… **COMPLETED**
  - [x] Multi-format processing using Docling âœ… **UPGRADED: Using Docling instead of PyPDF2**
  - [x] Advanced OCR and table extraction âœ…
  - [x] Multi-source support (OpenWebUI, Teams, Planner) âœ…
  - [x] Content validation and quality scoring âœ…
- [x] Implement Chunker class âœ… **INTEGRATED into DocumentProcessor**
  - [x] Overlapping text splitter âœ…
  - [x] Configurable chunk size/overlap âœ…
  - [x] Metadata preservation âœ…
- [x] Implement Embeddings Generator âœ… **COMPLETED**
  - [x] sentence-transformers integration (all-mpnet-base-v2) âœ…
  - [x] 768-dimensional embeddings âœ…
  - [x] Batch processing and async support âœ…
  - [x] LRU caching for performance âœ…
- [x] Implement Vector Store âœ… **COMPLETED**
  - [x] pgvector integration with IVFFLAT indexing âœ…
  - [x] Multi-source schema support âœ…
  - [x] CRUD operations âœ…
  - [x] Similarity search with source attribution âœ…

**Deliverables:**
- âœ… Documents can be processed and chunked
- âœ… Embeddings generated and stored in pgvector (768-dim)
- âœ… Multi-source semantic search working
- âœ… **BONUS: Advanced document processing with Docling**

---

### **Phase 3: OpenWebUI Integration (Week 1 - Days 6-7)**

**Goal:** First working document source

**Tasks:**
- [x] Implement OpenWebUIHandler âœ… **INTEGRATED into main.py**
  - [x] File validation âœ…
  - [x] Metadata extraction âœ…
  - [x] Upload handling âœ…
- [x] Create /api/upload endpoint âœ… **COMPLETED**
- [x] Create /api/query endpoint âœ… **COMPLETED**
- [x] Test with OpenWebUI Knowledge Base âœ… **WORKING**
- [x] Document OpenWebUI configuration âœ…

**Deliverables:**
- âœ… Users can upload docs via OpenWebUI
- âœ… Documents are processed and searchable
- âœ… Queries return relevant results

**Testing:**
```bash
# Upload document
curl -X POST http://localhost:7120/api/upload \
  -F "file=@test-document.pdf" \
  -F "source=openwebui" \
  -F "user_id=test-user"

# Query documents
curl -X POST http://localhost:7120/api/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What are the key milestones?", "top_k": 5}'
```

---

### **Phase 4: Teams Integration (Week 2 - Days 1-3)**

**Goal:** Enable Teams chat attachments

**Tasks:**
- [x] Implement TeamsHandler âœ… **COMPLETED**
  - [x] File download from Teams âœ…
  - [x] Conversation context extraction âœ…
  - [x] User attribution âœ…
- [x] Enhance teams-bot to handle attachments âœ… **COMPLETED**
  - [x] Detect file attachments âœ…
  - [x] Download file content âœ…
  - [x] Forward to rag-service âœ…
  - [x] Send confirmation message âœ…
- [x] Test end-to-end Teams â†’ RAG flow âœ… **COMPLETED**
- [x] Document Teams configuration âœ… **COMPLETED**

**Deliverables:**
- âœ… Users can attach files in Teams chat
- âœ… Files are automatically processed
- âœ… Users receive confirmation
- âœ… Files are queryable

**User Experience:**
```
User in Teams: [Attaches project-charter.pdf]
Bot: "âœ… Processed project-charter.pdf (3 pages, 15 chunks)
      You can now ask questions about it!"

User: "What are the key milestones?"
Bot: [Queries rag-service]
     "Based on project-charter.pdf, the key milestones are:
      1. Requirements complete by Feb 15
      2. Design approval by Mar 1
      3. Development complete by Apr 30"
```

---

### **Phase 5: Planner Integration (Week 2 - Days 4-5)**

**Goal:** Automatic processing of Planner attachments

**Tasks:**
- [ ] Implement PlannerHandler
  - [ ] Task attachment detection
  - [ ] File download via Graph API
  - [ ] Task context extraction
- [ ] Create Planner monitoring service
  - [ ] Poll for new task attachments
  - [ ] Track processed attachments
  - [ ] Handle updates/deletions
- [ ] Implement webhook support (optional)
- [ ] Test with real Planner tasks
- [ ] Document Planner configuration

**Deliverables:**
- âœ… Planner attachments automatically processed
- âœ… Files linked to tasks in metadata
- âœ… Queries can filter by task
- âœ… Monitoring service runs reliably

**Monitoring Service:**
```python
# Runs every 5 minutes
while True:
    tasks = await graph_client.get_all_tasks()
    for task in tasks:
        attachments = await graph_client.get_task_attachments(task.id)
        for attachment in attachments:
            if not already_processed(attachment.id):
                await process_attachment(attachment, task)
    await asyncio.sleep(300)
```

---

### **Phase 6: Unified Query Interface (Week 2 - Days 6-7)**

**Goal:** Query across all sources with attribution

**Tasks:**
- [ ] Implement UnifiedQueryService
  - [ ] Cross-source semantic search
  - [ ] Source filtering
  - [ ] Result ranking
  - [ ] Source attribution
- [ ] Implement RAG Engine
  - [ ] Context retrieval
  - [ ] Prompt construction
  - [ ] Response generation
- [ ] Add query analytics
- [ ] Performance optimization
- [ ] Comprehensive testing

**Deliverables:**
- âœ… Single query searches all sources
- âœ… Results include source attribution
- âœ… Filtering by source/task works
- âœ… Performance is acceptable (<500ms)

**Query Examples:**
```python
# Query all sources
results = await query_service.query("What is the project timeline?")

# Query specific source
results = await query_service.query(
    "What is the project timeline?",
    filters={"source": "planner"}
)

# Query specific task
results = await query_service.query(
    "What are the requirements?",
    filters={"task_id": "task-123"}
)
```

---

## Database Schema

```sql
-- Documents table
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    filename VARCHAR(255) NOT NULL,
    source VARCHAR(50) NOT NULL,  -- 'openwebui', 'teams', 'planner'
    source_id VARCHAR(255),  -- task_id, message_id, etc.
    uploaded_by VARCHAR(255),
    uploaded_at TIMESTAMP NOT NULL DEFAULT NOW(),
    content_type VARCHAR(100),
    file_size INTEGER,
    task_id VARCHAR(255),  -- For Planner attachments
    task_title VARCHAR(500),
    conversation_id VARCHAR(255),  -- For Teams messages
    metadata JSONB,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Document chunks table
CREATE TABLE document_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    embedding vector(768),  -- pgvector
    metadata JSONB,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    UNIQUE(document_id, chunk_index)
);

-- Indexes for performance
CREATE INDEX idx_documents_source ON documents(source);
CREATE INDEX idx_documents_task_id ON documents(task_id);
CREATE INDEX idx_documents_uploaded_by ON documents(uploaded_by);
CREATE INDEX idx_document_chunks_document_id ON document_chunks(document_id);

-- Vector similarity search index
CREATE INDEX ON document_chunks USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

---

## API Endpoints

### **Upload Endpoint**
```
POST /api/upload
Content-Type: multipart/form-data

Parameters:
- file: File (required)
- source: string (openwebui|teams|planner)
- source_id: string (optional)
- user_id: string (optional)
- task_id: string (optional, for Planner)
- task_title: string (optional, for Planner)
- conversation_id: string (optional, for Teams)

Response:
{
  "document_id": "uuid",
  "filename": "project-charter.pdf",
  "source": "teams",
  "chunks": 15,
  "processing_time": 2.3,
  "success": true
}
```

### **Query Endpoint**
```
POST /api/query
Content-Type: application/json

Body:
{
  "query": "What are the key milestones?",
  "top_k": 5,
  "filters": {
    "source": "planner",  // optional
    "task_id": "task-123"  // optional
  }
}

Response:
{
  "query": "What are the key milestones?",
  "results": [
    {
      "content": "Key milestones include...",
      "score": 0.92,
      "source": "planner",
      "filename": "project-charter.pdf",
      "task_id": "task-123",
      "task_title": "Project Planning",
      "chunk_index": 3
    }
  ],
  "total_results": 5,
  "processing_time": 0.15
}
```

### **Health Endpoint**
```
GET /health

Response:
{
  "status": "healthy",
  "service": "rag-service",
  "version": "1.0.0",
  "database": "connected",
  "embeddings_model": "loaded",
  "sources": {
    "openwebui": "enabled",
    "teams": "enabled",
    "planner": "enabled"
  }
}
```

---

## Next Steps

1. **Setup Environment:**
   ```bash
   cd rag-service
   uv venv --python 3.11
   source .venv/bin/activate
   uv pip install -r requirements.txt
   ```

2. **Create Database Schema:**
   ```bash
   # Run SQL schema creation
   psql -U itp_user -d intelligent_teams_planner -f schema.sql
   ```

3. **Start Implementation:**
   - Begin with Phase 2 (Document Processing Pipeline)
   - Test each component independently
   - Integrate incrementally

4. **Testing Strategy:**
   - Unit tests for each component
   - Integration tests for end-to-end flow
   - Performance tests for large documents
   - Load tests for concurrent uploads

---

## âœ… Implementation Status

**Current Status:** ğŸŸ¢ **PHASE 4 COMPLETED** - Teams Integration fully operational
**Next Action:** Begin Phase 5 (Planner Integration)
**Timeline:** Phases 2-4 completed ahead of schedule with modern tooling

## ğŸš€ Key Implementation Achievements

### **âœ… Core Infrastructure Completed**
- **PostgresClient**: Full async connection management with health monitoring
- **VectorStore**: pgvector with IVFFLAT indexing, multi-source schema support
- **DocumentProcessor**: Advanced Docling integration with OCR and structure extraction
- **EmbeddingGenerator**: 768-dimensional embeddings with caching and batch processing
- **SemanticSearchEngine**: Unified search with source attribution and hybrid ranking

### **âœ… Alignment with Implementation Plan**
- **Database Schema**: Updated to support multi-source architecture (documents, document_chunks, search_analytics)
- **API Endpoints**: Aligned with specification (/api/upload, /api/query, /health)
- **Multi-Source Support**: OpenWebUI, Teams, Planner sources fully supported
- **Vector Dimensions**: Upgraded to 768 dimensions using all-mpnet-base-v2 model
- **Advanced Processing**: Docling integration provides superior document parsing

### **âœ… Technical Enhancements**
- **Modern Document Processing**: Docling replaces basic PyPDF2 approach
- **Async Architecture**: Full async/await support throughout the stack
- **Production-Ready**: Health checks, error handling, logging, validation
- **Performance Optimized**: Vector indexing, embedding caching, batch processing
- **Multi-Source Ready**: Source attribution, filtering, and unified search

### **ğŸ“‹ Next Development Steps**
1. **Phase 4**: Teams bot enhancement for file attachment processing âœ… **COMPLETED**
2. **Phase 5**: Planner monitoring service for automatic attachment processing (NEXT)
3. **Phase 6**: Production deployment with full integration testing

**Quality Status:** âœ… Production-ready RAG service with OpenWebUI and Teams integration complete

### **âœ… Phase 4 Achievements - Teams Integration**
- **TeamsAttachmentHandler**: Complete secure file processing with SSRF protection, dangerous file blocking, and size limits
- **Bot Framework Integration**: Fixed authentication issues and enabled seamless file forwarding
- **End-to-End Workflow**: Teams attachments â†’ RAG processing â†’ semantic search fully operational
- **Security Features**: Path traversal prevention, URL validation, file sanitization, host whitelisting
- **User Experience**: Automatic file processing with confirmation messages and queryable documents

