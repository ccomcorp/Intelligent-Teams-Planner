# Story 3.4: Development Environment Automation

## Status
Draft

## Story

**As a** developer,
**I want** automated development environment setup and management,
**so that** I can focus on coding rather than environment configuration and maintenance.

## Acceptance Criteria

1. **One-Command Setup**: Complete development environment setup with single command
2. **Environment Consistency**: Identical development and production environments
3. **Automated Dependencies**: Automatic installation and configuration of all dependencies
4. **IDE Integration**: Seamless integration with popular IDEs and development tools
5. **Hot Reload Support**: Real-time code changes reflected without manual restarts
6. **Testing Environment**: Automated test environment provisioning and cleanup
7. **Data Seeding**: Automated database and cache seeding with realistic test data
8. **Environment Isolation**: Multiple isolated environments per developer

## Tasks / Subtasks

- [ ] Task 1: Create One-Command Development Setup (AC: 1)
  - [ ] Create development environment bootstrap script
  - [ ] Implement Docker Compose development configuration
  - [ ] Add automatic dependency resolution and installation
  - [ ] Create environment health checking and validation
  - [ ] Implement development environment teardown and cleanup

- [ ] Task 2: Ensure Environment Consistency (AC: 2)
  - [ ] Create development Docker images matching production
  - [ ] Implement configuration synchronization between environments
  - [ ] Add environment validation and compliance checking
  - [ ] Create environment drift detection for development
  - [ ] Implement automated environment updates

- [ ] Task 3: Automate Dependency Management (AC: 3)
  - [ ] Create dependency installation automation
  - [ ] Implement version pinning and compatibility checking
  - [ ] Add automatic environment variable configuration
  - [ ] Create service dependency orchestration
  - [ ] Implement dependency health monitoring

- [ ] Task 4: Integrate with Development Tools (AC: 4)
  - [ ] Create VS Code development container configuration
  - [ ] Implement PyCharm/IntelliJ integration
  - [ ] Add debugging configuration for all services
  - [ ] Create code formatting and linting integration
  - [ ] Implement automated code generation tools

- [ ] Task 5: Implement Hot Reload Capabilities (AC: 5)
  - [ ] Configure file watching and automatic reloading
  - [ ] Implement hot module replacement for frontend components
  - [ ] Add automatic service restart on code changes
  - [ ] Create incremental build optimization
  - [ ] Implement selective service reloading

- [ ] Task 6: Automate Testing Environment Management (AC: 6)
  - [ ] Create isolated testing environment provisioning
  - [ ] Implement test database creation and cleanup
  - [ ] Add automated test data generation and seeding
  - [ ] Create testing environment lifecycle management
  - [ ] Implement parallel testing environment support

- [ ] Task 7: Implement Automated Data Seeding (AC: 7)
  - [ ] Create realistic test data generation
  - [ ] Implement database migration and seeding automation
  - [ ] Add cache warming with test data
  - [ ] Create data anonymization for production data
  - [ ] Implement incremental data updates

- [ ] Task 8: Enable Environment Isolation (AC: 8)
  - [ ] Create developer-specific environment namespaces
  - [ ] Implement port allocation and conflict resolution
  - [ ] Add resource isolation and quota management
  - [ ] Create environment discovery and routing
  - [ ] Implement environment cleanup and resource reclamation

## Dev Notes

### Relevant Source Tree Information

**Development Environment Structure:**
```
dev-environment/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                 # NEW FILE - One-command setup
‚îÇ   ‚îú‚îÄ‚îÄ teardown.sh              # NEW FILE - Environment cleanup
‚îÇ   ‚îú‚îÄ‚îÄ health-check.sh          # NEW FILE - Environment validation
‚îÇ   ‚îú‚îÄ‚îÄ update.sh                # NEW FILE - Environment updates
‚îÇ   ‚îî‚îÄ‚îÄ seed-data.sh             # NEW FILE - Data seeding
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.dev.yml   # NEW FILE - Development compose
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.test.yml  # NEW FILE - Testing compose
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.dev           # NEW FILE - Development images
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore            # NEW FILE - Docker ignore rules
‚îú‚îÄ‚îÄ .devcontainer/
‚îÇ   ‚îú‚îÄ‚îÄ devcontainer.json        # NEW FILE - VS Code dev container
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml       # NEW FILE - Dev container compose
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile               # NEW FILE - Dev container image
‚îú‚îÄ‚îÄ ide-configs/
‚îÇ   ‚îú‚îÄ‚îÄ vscode/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.json        # NEW FILE - VS Code settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ launch.json          # NEW FILE - Debug configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks.json           # NEW FILE - Build tasks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extensions.json      # NEW FILE - Recommended extensions
‚îÇ   ‚îú‚îÄ‚îÄ intellij/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .idea/               # NEW DIR - IntelliJ configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run-configurations/  # NEW DIR - Run configs
‚îÇ   ‚îî‚îÄ‚îÄ vim/
‚îÇ       ‚îú‚îÄ‚îÄ .vimrc               # NEW FILE - Vim configuration
‚îÇ       ‚îî‚îÄ‚îÄ plugins.txt          # NEW FILE - Vim plugins
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ seeds/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ users.sql            # NEW FILE - User test data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plans.sql            # NEW FILE - Plan test data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks.sql            # NEW FILE - Task test data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ permissions.sql      # NEW FILE - Permission data
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test-users.json      # NEW FILE - Test user fixtures
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test-plans.json      # NEW FILE - Test plan fixtures
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test-tasks.json      # NEW FILE - Test task fixtures
‚îÇ   ‚îî‚îÄ‚îÄ generators/
‚îÇ       ‚îú‚îÄ‚îÄ generate-users.py    # NEW FILE - User data generator
‚îÇ       ‚îú‚îÄ‚îÄ generate-plans.py    # NEW FILE - Plan data generator
‚îÇ       ‚îî‚îÄ‚îÄ generate-tasks.py    # NEW FILE - Task data generator
‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îú‚îÄ‚îÄ base.env                 # NEW FILE - Base environment vars
‚îÇ   ‚îú‚îÄ‚îÄ development.env          # NEW FILE - Dev-specific vars
‚îÇ   ‚îú‚îÄ‚îÄ testing.env              # NEW FILE - Test-specific vars
‚îÇ   ‚îî‚îÄ‚îÄ local.env.example        # NEW FILE - Local overrides example
‚îî‚îÄ‚îÄ tools/
    ‚îú‚îÄ‚îÄ wait-for-services.sh     # NEW FILE - Service readiness check
    ‚îú‚îÄ‚îÄ port-allocation.sh       # NEW FILE - Dynamic port allocation
    ‚îú‚îÄ‚îÄ environment-manager.py   # NEW FILE - Environment management
    ‚îî‚îÄ‚îÄ resource-monitor.sh      # NEW FILE - Resource monitoring
```

### Technical Implementation Details

**One-Command Setup Script:**
```bash\n#!/bin/bash\n# dev-environment/scripts/setup.sh\n\nset -e\n\nDEV_ENV_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/..\"\nPROJECT_ROOT=\"$(cd \"$DEV_ENV_DIR/..\" && pwd)\"\nDEVELOPER_ID=\"${USER}-$(date +%s)\"\n\necho \"üöÄ Setting up Intelligent Teams Planner development environment...\"\necho \"Developer ID: $DEVELOPER_ID\"\necho \"Project Root: $PROJECT_ROOT\"\n\n# Check prerequisites\necho \"üìã Checking prerequisites...\"\ncommand -v docker >/dev/null 2>&1 || { echo \"‚ùå Docker is required but not installed. Aborting.\" >&2; exit 1; }\ncommand -v docker-compose >/dev/null 2>&1 || { echo \"‚ùå Docker Compose is required but not installed. Aborting.\" >&2; exit 1; }\ncommand -v git >/dev/null 2>&1 || { echo \"‚ùå Git is required but not installed. Aborting.\" >&2; exit 1; }\n\n# Create developer-specific environment\necho \"üèóÔ∏è  Creating isolated development environment...\"\nDEV_NAMESPACE=\"planner-dev-$DEVELOPER_ID\"\nexport DEV_NAMESPACE\nexport DEVELOPER_ID\n\n# Generate dynamic port allocations\necho \"üîå Allocating ports...\"\nBASE_PORT=3000\nexport TEAMS_BOT_PORT=$((BASE_PORT + 1))\nexport OPENWEBUI_PORT=$((BASE_PORT + 2))\nexport MCP_SERVER_PORT=$((BASE_PORT + 3))\nexport MCPO_PROXY_PORT=$((BASE_PORT + 4))\nexport POSTGRES_PORT=$((BASE_PORT + 5))\nexport REDIS_PORT=$((BASE_PORT + 6))\nexport PROMETHEUS_PORT=$((BASE_PORT + 7))\nexport GRAFANA_PORT=$((BASE_PORT + 8))\n\necho \"üìù Port allocations:\"\necho \"  Teams Bot: $TEAMS_BOT_PORT\"\necho \"  OpenWebUI: $OPENWEBUI_PORT\"\necho \"  MCP Server: $MCP_SERVER_PORT\"\necho \"  MCPO Proxy: $MCPO_PROXY_PORT\"\necho \"  PostgreSQL: $POSTGRES_PORT\"\necho \"  Redis: $REDIS_PORT\"\necho \"  Prometheus: $PROMETHEUS_PORT\"\necho \"  Grafana: $GRAFANA_PORT\"\n\n# Create environment configuration\necho \"‚öôÔ∏è  Generating environment configuration...\"\nenvsubst < \"$DEV_ENV_DIR/environments/development.env\" > \"$DEV_ENV_DIR/.env.local\"\n\n# Create Docker network\necho \"üåê Creating Docker network...\"\ndocker network create \"$DEV_NAMESPACE\" 2>/dev/null || echo \"Network already exists\"\n\n# Build development images\necho \"üî® Building development images...\"\ndocker-compose -f \"$DEV_ENV_DIR/docker/docker-compose.dev.yml\" build --parallel\n\n# Start infrastructure services\necho \"üìä Starting infrastructure services...\"\ndocker-compose -f \"$DEV_ENV_DIR/docker/docker-compose.dev.yml\" up -d postgres redis prometheus grafana\n\n# Wait for services to be ready\necho \"‚è≥ Waiting for services to be ready...\"\n\"$DEV_ENV_DIR/tools/wait-for-services.sh\"\n\n# Seed database\necho \"üå± Seeding database with test data...\"\n\"$DEV_ENV_DIR/scripts/seed-data.sh\"\n\n# Start application services\necho \"üöÄ Starting application services...\"\ndocker-compose -f \"$DEV_ENV_DIR/docker/docker-compose.dev.yml\" up -d\n\n# Wait for all services\necho \"‚è≥ Waiting for all services to be ready...\"\nsleep 30\n\"$DEV_ENV_DIR/scripts/health-check.sh\"\n\n# Setup IDE configurations\necho \"üõ†Ô∏è  Setting up IDE configurations...\"\nif command -v code >/dev/null 2>&1; then\n    echo \"  Configuring VS Code...\"\n    cp -r \"$DEV_ENV_DIR/ide-configs/vscode/.vscode\" \"$PROJECT_ROOT/\"\nfi\n\nif [ -d \"$HOME/.config/JetBrains\" ]; then\n    echo \"  Configuring IntelliJ IDEA...\"\n    # Copy IntelliJ configurations\nfi\n\n# Display access information\necho \"‚úÖ Development environment setup complete!\"\necho \"\"\necho \"üåç Access URLs:\"\necho \"  OpenWebUI: http://localhost:$OPENWEBUI_PORT\"\necho \"  Teams Bot Webhook: http://localhost:$TEAMS_BOT_PORT\"\necho \"  MCP Server: http://localhost:$MCP_SERVER_PORT\"\necho \"  Grafana: http://localhost:$GRAFANA_PORT (admin/admin)\"\necho \"  Prometheus: http://localhost:$PROMETHEUS_PORT\"\necho \"\"\necho \"üìù Environment file: $DEV_ENV_DIR/.env.local\"\necho \"üîç Health check: $DEV_ENV_DIR/scripts/health-check.sh\"\necho \"üßπ Cleanup: $DEV_ENV_DIR/scripts/teardown.sh\"\necho \"\"\necho \"üéØ Next steps:\"\necho \"  1. Open your IDE and start coding\"\necho \"  2. Run tests: cd $PROJECT_ROOT && pytest\"\necho \"  3. View logs: docker-compose -f $DEV_ENV_DIR/docker/docker-compose.dev.yml logs -f\"\necho \"\"\necho \"Happy coding! üéâ\"\n```\n\n**Docker Compose Development Configuration:**\n```yaml\n# dev-environment/docker/docker-compose.dev.yml\nversion: '3.8'\n\nnetworks:\n  planner-dev:\n    name: ${DEV_NAMESPACE:-planner-dev}\n    external: true\n\nvolumes:\n  postgres_data:\n    name: ${DEV_NAMESPACE:-planner-dev}_postgres_data\n  redis_data:\n    name: ${DEV_NAMESPACE:-planner-dev}_redis_data\n  prometheus_data:\n    name: ${DEV_NAMESPACE:-planner-dev}_prometheus_data\n  grafana_data:\n    name: ${DEV_NAMESPACE:-planner-dev}_grafana_data\n\nservices:\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: planner_dev\n      POSTGRES_USER: planner\n      POSTGRES_PASSWORD: devpassword\n      POSTGRES_INITDB_ARGS: \"--encoding=UTF-8 --lc-collate=C --lc-ctype=C\"\n    ports:\n      - \"${POSTGRES_PORT:-5432}:5432\"\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ../data/seeds:/docker-entrypoint-initdb.d:ro\n    networks:\n      - planner-dev\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U planner -d planner_dev\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  redis:\n    image: redis:7-alpine\n    command: redis-server --appendonly yes --requirepass devpassword\n    ports:\n      - \"${REDIS_PORT:-6379}:6379\"\n    volumes:\n      - redis_data:/data\n    networks:\n      - planner-dev\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"-a\", \"devpassword\", \"ping\"]\n      interval: 10s\n      timeout: 3s\n      retries: 5\n\n  teams-bot:\n    build:\n      context: ../../teams-bot\n      dockerfile: Dockerfile.dev\n    environment:\n      - DATABASE_URL=postgresql://planner:devpassword@postgres:5432/planner_dev\n      - REDIS_URL=redis://:devpassword@redis:6379\n      - OPENWEBUI_URL=http://openwebui:8080\n      - DEVELOPMENT_MODE=true\n      - HOT_RELOAD=true\n    ports:\n      - \"${TEAMS_BOT_PORT:-3978}:3978\"\n    volumes:\n      - ../../teams-bot:/app:cached\n      - /app/node_modules\n    networks:\n      - planner-dev\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n\n  openwebui:\n    image: ghcr.io/open-webui/open-webui:main\n    environment:\n      - OPENWEBUI_SECRET_KEY=dev-secret-key-change-me\n      - WEBUI_AUTH=false\n      - ENABLE_RAG_WEB_SEARCH=true\n      - ENABLE_RAG_LOCAL_WEB_FETCH=true\n      - DEVELOPMENT_MODE=true\n    ports:\n      - \"${OPENWEBUI_PORT:-8080}:8080\"\n    volumes:\n      - ../../openwebui/data:/app/backend/data\n      - ../../openwebui/config:/app/backend/config\n    networks:\n      - planner-dev\n    restart: unless-stopped\n\n  planner-mcp-server:\n    build:\n      context: ../../planner-mcp-server\n      dockerfile: Dockerfile.dev\n    environment:\n      - DATABASE_URL=postgresql://planner:devpassword@postgres:5432/planner_dev\n      - REDIS_URL=redis://:devpassword@redis:6379\n      - DEVELOPMENT_MODE=true\n      - HOT_RELOAD=true\n      - LOG_LEVEL=DEBUG\n    ports:\n      - \"${MCP_SERVER_PORT:-8000}:8000\"\n    volumes:\n      - ../../planner-mcp-server:/app:cached\n      - /app/.venv\n    networks:\n      - planner-dev\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n\n  mcpo-proxy:\n    build:\n      context: ../../mcpo-proxy\n      dockerfile: Dockerfile.dev\n    environment:\n      - MCP_SERVER_URL=http://planner-mcp-server:8000\n      - OPENWEBUI_URL=http://openwebui:8080\n      - DEVELOPMENT_MODE=true\n      - HOT_RELOAD=true\n      - LOG_LEVEL=DEBUG\n    ports:\n      - \"${MCPO_PROXY_PORT:-8001}:8001\"\n    volumes:\n      - ../../mcpo-proxy:/app:cached\n      - /app/node_modules\n    networks:\n      - planner-dev\n    depends_on:\n      - planner-mcp-server\n      - openwebui\n    restart: unless-stopped\n\n  prometheus:\n    image: prom/prometheus:latest\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/etc/prometheus/console_libraries'\n      - '--web.console.templates=/etc/prometheus/consoles'\n      - '--storage.tsdb.retention.time=200h'\n      - '--web.enable-lifecycle'\n    ports:\n      - \"${PROMETHEUS_PORT:-9090}:9090\"\n    volumes:\n      - ../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro\n      - prometheus_data:/prometheus\n    networks:\n      - planner-dev\n    restart: unless-stopped\n\n  grafana:\n    image: grafana/grafana:latest\n    environment:\n      - GF_SECURITY_ADMIN_USER=admin\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n      - GF_USERS_ALLOW_SIGN_UP=false\n      - GF_INSTALL_PLUGINS=grafana-piechart-panel\n    ports:\n      - \"${GRAFANA_PORT:-3000}:3000\"\n    volumes:\n      - grafana_data:/var/lib/grafana\n      - ../monitoring/grafana/provisioning:/etc/grafana/provisioning:ro\n      - ../monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro\n    networks:\n      - planner-dev\n    depends_on:\n      - prometheus\n    restart: unless-stopped\n```\n\n**VS Code Development Container:**\n```json\n{\n  \"name\": \"Intelligent Teams Planner Development\",\n  \"dockerComposeFile\": [\n    \"../docker/docker-compose.dev.yml\"\n  ],\n  \"service\": \"planner-mcp-server\",\n  \"workspaceFolder\": \"/app\",\n  \"shutdownAction\": \"stopCompose\",\n  \n  \"features\": {\n    \"ghcr.io/devcontainers/features/python:1\": {\n      \"version\": \"3.11\",\n      \"installTools\": true\n    },\n    \"ghcr.io/devcontainers/features/node:1\": {\n      \"version\": \"18\"\n    },\n    \"ghcr.io/devcontainers/features/docker-in-docker:2\": {},\n    \"ghcr.io/devcontainers/features/kubectl-helm-minikube:1\": {\n      \"version\": \"latest\",\n      \"helm\": \"latest\",\n      \"minikube\": \"none\"\n    }\n  },\n  \n  \"customizations\": {\n    \"vscode\": {\n      \"settings\": {\n        \"python.defaultInterpreterPath\": \"/app/.venv/bin/python\",\n        \"python.linting.enabled\": true,\n        \"python.linting.pylintEnabled\": true,\n        \"python.formatting.provider\": \"black\",\n        \"python.testing.pytestEnabled\": true,\n        \"python.testing.pytestArgs\": [\"tests\"],\n        \"editor.formatOnSave\": true,\n        \"editor.codeActionsOnSave\": {\n          \"source.organizeImports\": true\n        },\n        \"files.exclude\": {\n          \"**/__pycache__\": true,\n          \"**/.pytest_cache\": true,\n          \"**/.coverage\": true\n        }\n      },\n      \n      \"extensions\": [\n        \"ms-python.python\",\n        \"ms-python.pylint\",\n        \"ms-python.black-formatter\",\n        \"ms-python.isort\",\n        \"ms-toolsai.jupyter\",\n        \"ms-vscode.docker\",\n        \"ms-kubernetes-tools.vscode-kubernetes-tools\",\n        \"redhat.vscode-yaml\",\n        \"bradlc.vscode-tailwindcss\",\n        \"esbenp.prettier-vscode\",\n        \"github.copilot\",\n        \"github.copilot-chat\",\n        \"github.vscode-pull-request-github\",\n        \"gruntfuggly.todo-tree\",\n        \"streetsidesoftware.code-spell-checker\"\n      ]\n    }\n  },\n  \n  \"forwardPorts\": [\n    3978,\n    8080,\n    8000,\n    8001,\n    5432,\n    6379,\n    9090,\n    3000\n  ],\n  \n  \"portsAttributes\": {\n    \"3978\": {\n      \"label\": \"Teams Bot\",\n      \"onAutoForward\": \"notify\"\n    },\n    \"8080\": {\n      \"label\": \"OpenWebUI\",\n      \"onAutoForward\": \"openBrowser\"\n    },\n    \"8000\": {\n      \"label\": \"MCP Server\",\n      \"onAutoForward\": \"notify\"\n    },\n    \"8001\": {\n      \"label\": \"MCPO Proxy\",\n      \"onAutoForward\": \"notify\"\n    },\n    \"9090\": {\n      \"label\": \"Prometheus\",\n      \"onAutoForward\": \"ignore\"\n    },\n    \"3000\": {\n      \"label\": \"Grafana\",\n      \"onAutoForward\": \"ignore\"\n    }\n  },\n  \n  \"postCreateCommand\": \"pip install -e .\",\n  \"postStartCommand\": \"python -m pytest --version\",\n  \n  \"remoteUser\": \"vscode\",\n  \"containerUser\": \"vscode\"\n}\n```\n\n### Environment Variables (Development Configuration)\n\n```env\n# dev-environment/environments/development.env\n# Base Development Environment Configuration\n\n# Developer Identity\nDEVELOPER_ID=${DEVELOPER_ID}\nDEV_NAMESPACE=${DEV_NAMESPACE}\n\n# Application Ports\nTEAMS_BOT_PORT=${TEAMS_BOT_PORT:-3978}\nOPENWEBUI_PORT=${OPENWEBUI_PORT:-8080}\nMCP_SERVER_PORT=${MCP_SERVER_PORT:-8000}\nMCPO_PROXY_PORT=${MCPO_PROXY_PORT:-8001}\n\n# Infrastructure Ports\nPOSTGRES_PORT=${POSTGRES_PORT:-5432}\nREDIS_PORT=${REDIS_PORT:-6379}\nPROMETHEUS_PORT=${PROMETHEUS_PORT:-9090}\nGRAFANA_PORT=${GRAFANA_PORT:-3000}\n\n# Database Configuration\nDATABASE_URL=postgresql://planner:devpassword@localhost:${POSTGRES_PORT}/planner_dev\nDATABASE_HOST=localhost\nDATABASE_PORT=${POSTGRES_PORT}\nDATABASE_NAME=planner_dev\nDATABASE_USER=planner\nDATABASE_PASSWORD=devpassword\n\n# Redis Configuration\nREDIS_URL=redis://:devpassword@localhost:${REDIS_PORT}\nREDIS_HOST=localhost\nREDIS_PORT=${REDIS_PORT}\nREDIS_PASSWORD=devpassword\nREDIS_DB=0\n\n# Development Mode Settings\nDEVELOPMENT_MODE=true\nDEBUG=true\nHOT_RELOAD=true\nAUTO_RELOAD=true\nLOG_LEVEL=DEBUG\n\n# API Configuration\nOPENWEBUI_URL=http://localhost:${OPENWEBUI_PORT}\nMCP_SERVER_URL=http://localhost:${MCP_SERVER_PORT}\nMCPO_PROXY_URL=http://localhost:${MCPO_PROXY_PORT}\n\n# Authentication (Development)\nOPENWEBUI_SECRET_KEY=dev-secret-key-change-me\nWEBUI_AUTH=false\nSKIP_AUTH=true\n\n# Microsoft Graph (Mock/Test)\nAZURE_CLIENT_ID=test-client-id\nAZURE_CLIENT_SECRET=test-client-secret\nAZURE_TENANT_ID=test-tenant-id\nMOCK_GRAPH_API=true\n\n# Feature Flags\nENABLE_RAG_WEB_SEARCH=true\nENABLE_RAG_LOCAL_WEB_FETCH=true\nENABLE_TELEMETRY=false\nENABLE_ANALYTICS=false\n\n# Testing Configuration\nTEST_DATABASE_URL=postgresql://planner:devpassword@localhost:${POSTGRES_PORT}/planner_test\nTEST_REDIS_URL=redis://:devpassword@localhost:${REDIS_PORT}/1\nPYTEST_PARALLEL=true\nTEST_COVERAGE_THRESHOLD=80\n\n# File Watching (Development)\nWATCH_FILES=true\nWATCH_EXTENSIONS=.py,.js,.ts,.yml,.yaml,.json\nWATCH_IGNORE_PATTERNS=__pycache__,node_modules,.git,.pytest_cache\n\n# Performance (Development)\nWORKERS=1\nTHREADS=1\nDEBUG_TOOLBAR=true\nPROFILING_ENABLED=true\n\n# Monitoring (Development)\nPROMETHEUS_ENABLED=true\nGRAFANA_ENABLED=true\nMETRICS_EXPORT_INTERVAL=10\nLOG_STRUCTURED=false\n```\n\n### Hot Reload Configuration\n\n**File Watcher Script:**\n```python\n#!/usr/bin/env python3\n# dev-environment/tools/file-watcher.py\n\nimport os\nimport sys\nimport time\nimport subprocess\nfrom pathlib import Path\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\n\nclass HotReloadHandler(FileSystemEventHandler):\n    def __init__(self, service_name, restart_command):\n        self.service_name = service_name\n        self.restart_command = restart_command\n        self.last_restart = 0\n        self.debounce_delay = 2  # seconds\n    \n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        \n        # Check file extension\n        if not any(event.src_path.endswith(ext) for ext in ['.py', '.js', '.ts', '.yml', '.yaml']):\n            return\n        \n        # Ignore certain paths\n        ignore_patterns = ['__pycache__', 'node_modules', '.git', '.pytest_cache', '.coverage']\n        if any(pattern in event.src_path for pattern in ignore_patterns):\n            return\n        \n        current_time = time.time()\n        if current_time - self.last_restart < self.debounce_delay:\n            return\n        \n        print(f\"üîÑ File changed: {event.src_path}\")\n        print(f\"üîÉ Restarting {self.service_name}...\")\n        \n        try:\n            result = subprocess.run(self.restart_command, shell=True, capture_output=True, text=True)\n            if result.returncode == 0:\n                print(f\"‚úÖ {self.service_name} restarted successfully\")\n            else:\n                print(f\"‚ùå Failed to restart {self.service_name}: {result.stderr}\")\n        except Exception as e:\n            print(f\"‚ùå Error restarting {self.service_name}: {e}\")\n        \n        self.last_restart = current_time\n\ndef main():\n    if len(sys.argv) < 4:\n        print(\"Usage: python file-watcher.py <watch_path> <service_name> <restart_command>\")\n        sys.exit(1)\n    \n    watch_path = sys.argv[1]\n    service_name = sys.argv[2]\n    restart_command = sys.argv[3]\n    \n    event_handler = HotReloadHandler(service_name, restart_command)\n    observer = Observer()\n    observer.schedule(event_handler, watch_path, recursive=True)\n    \n    print(f\"üîç Watching {watch_path} for changes...\")\n    print(f\"üéØ Service: {service_name}\")\n    print(f\"üîÑ Restart command: {restart_command}\")\n    print(\"Press Ctrl+C to stop\")\n    \n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n        print(\"\\nüëã File watcher stopped\")\n    \n    observer.join()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Testing Environment Management\n\n**Test Environment Script:**\n```bash\n#!/bin/bash\n# dev-environment/scripts/test-environment.sh\n\nset -e\n\nTEST_ID=\"test-$(date +%s)\"\nTEST_NAMESPACE=\"planner-test-$TEST_ID\"\nTEST_COMPOSE_FILE=\"dev-environment/docker/docker-compose.test.yml\"\n\necho \"üß™ Creating isolated test environment: $TEST_NAMESPACE\"\n\n# Create test network\ndocker network create \"$TEST_NAMESPACE\" 2>/dev/null || true\n\n# Export test environment variables\nexport TEST_NAMESPACE\nexport TEST_ID\nexport POSTGRES_TEST_PORT=$((5432 + RANDOM % 1000))\nexport REDIS_TEST_PORT=$((6379 + RANDOM % 1000))\n\n# Start test infrastructure\necho \"üèóÔ∏è  Starting test infrastructure...\"\ndocker-compose -f \"$TEST_COMPOSE_FILE\" -p \"$TEST_NAMESPACE\" up -d postgres redis\n\n# Wait for services\necho \"‚è≥ Waiting for test services...\"\nsleep 10\n\n# Run database migrations\necho \"üóÑÔ∏è  Running database migrations...\"\nTEST_DATABASE_URL=\"postgresql://planner:testpassword@localhost:$POSTGRES_TEST_PORT/planner_test\"\nDATABASE_URL=\"$TEST_DATABASE_URL\" python -m alembic upgrade head\n\n# Seed test data\necho \"üå± Seeding test data...\"\nDATABASE_URL=\"$TEST_DATABASE_URL\" python dev-environment/data/generators/generate-test-data.py\n\n# Run tests\necho \"üß™ Running tests...\"\nif [ \"$1\" = \"--interactive\" ]; then\n    echo \"üéÆ Interactive test environment ready!\"\n    echo \"  Database: $TEST_DATABASE_URL\"\n    echo \"  Redis: redis://:testpassword@localhost:$REDIS_TEST_PORT\"\n    echo \"  Press Ctrl+C to cleanup and exit\"\n    \n    # Keep environment running\n    trap 'echo \"\\nüßπ Cleaning up test environment...\"; docker-compose -f \"$TEST_COMPOSE_FILE\" -p \"$TEST_NAMESPACE\" down -v; docker network rm \"$TEST_NAMESPACE\" 2>/dev/null || true; exit 0' INT\n    \n    while true; do\n        sleep 1\n    done\nelse\n    # Run tests and cleanup\n    TEST_DATABASE_URL=\"$TEST_DATABASE_URL\" \\\n    TEST_REDIS_URL=\"redis://:testpassword@localhost:$REDIS_TEST_PORT\" \\\n    python -m pytest \"${@:-tests/}\" -v\n    \n    TEST_EXIT_CODE=$?\n    \n    echo \"üßπ Cleaning up test environment...\"\n    docker-compose -f \"$TEST_COMPOSE_FILE\" -p \"$TEST_NAMESPACE\" down -v\n    docker network rm \"$TEST_NAMESPACE\" 2>/dev/null || true\n    \n    exit $TEST_EXIT_CODE\nfi\n```\n\n### Data Seeding and Generation\n\n**Test Data Generator:**\n```python\n#!/usr/bin/env python3\n# dev-environment/data/generators/generate-test-data.py\n\nimport os\nimport json\nimport random\nfrom datetime import datetime, timedelta\nfrom faker import Faker\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor\n\nfake = Faker()\nFaker.seed(42)  # For reproducible test data\n\ndef generate_users(count=50):\n    \"\"\"Generate realistic user test data\"\"\"\n    users = []\n    for i in range(count):\n        user = {\n            'id': f\"user-{i+1:03d}\",\n            'email': fake.email(),\n            'first_name': fake.first_name(),\n            'last_name': fake.last_name(),\n            'display_name': fake.name(),\n            'job_title': fake.job(),\n            'department': fake.random_element([\n                'Engineering', 'Product', 'Design', 'Marketing', \n                'Sales', 'Operations', 'Finance', 'HR'\n            ]),\n            'timezone': fake.timezone(),\n            'created_at': fake.date_time_between(start_date='-1y', end_date='now'),\n            'is_active': random.choice([True, True, True, False])  # 75% active\n        }\n        users.append(user)\n    return users\n\ndef generate_plans(users, count=20):\n    \"\"\"Generate test plans with realistic data\"\"\"\n    plans = []\n    for i in range(count):\n        owner = random.choice(users)\n        plan = {\n            'id': f\"plan-{i+1:03d}\",\n            'title': fake.catch_phrase(),\n            'description': fake.text(max_nb_chars=500),\n            'owner_id': owner['id'],\n            'created_at': fake.date_time_between(start_date='-6m', end_date='now'),\n            'due_date': fake.date_between(start_date='today', end_date='+3m'),\n            'status': random.choice(['active', 'completed', 'on_hold']),\n            'priority': random.choice(['low', 'medium', 'high', 'critical']),\n            'tags': fake.words(nb=random.randint(1, 5))\n        }\n        plans.append(plan)\n    return plans\n\ndef generate_tasks(users, plans, count=200):\n    \"\"\"Generate test tasks for plans\"\"\"\n    tasks = []\n    for i in range(count):\n        plan = random.choice(plans)\n        assignee = random.choice(users)\n        \n        task = {\n            'id': f\"task-{i+1:04d}\",\n            'title': fake.sentence(nb_words=6).rstrip('.'),\n            'description': fake.text(max_nb_chars=300),\n            'plan_id': plan['id'],\n            'assignee_id': assignee['id'],\n            'created_at': fake.date_time_between(\n                start_date=plan['created_at'], \n                end_date='now'\n            ),\n            'due_date': fake.date_between(start_date='today', end_date=plan['due_date']),\n            'status': random.choice([\n                'not_started', 'in_progress', 'completed', \n                'blocked', 'cancelled'\n            ]),\n            'priority': random.choice(['low', 'medium', 'high']),\n            'estimated_hours': random.randint(1, 40),\n            'actual_hours': random.randint(0, 50) if random.random() > 0.3 else None,\n            'completion_percentage': random.randint(0, 100),\n            'labels': fake.words(nb=random.randint(0, 3))\n        }\n        tasks.append(task)\n    return tasks\n\ndef seed_database():\n    \"\"\"Seed the database with generated test data\"\"\"\n    database_url = os.environ.get('DATABASE_URL') or os.environ.get('TEST_DATABASE_URL')\n    if not database_url:\n        raise ValueError(\"DATABASE_URL or TEST_DATABASE_URL environment variable required\")\n    \n    print(\"üå± Generating test data...\")\n    users = generate_users(50)\n    plans = generate_plans(users, 20)\n    tasks = generate_tasks(users, plans, 200)\n    \n    print(f\"Generated: {len(users)} users, {len(plans)} plans, {len(tasks)} tasks\")\n    \n    # Connect to database\n    conn = psycopg2.connect(database_url)\n    cur = conn.cursor(cursor_factory=RealDictCursor)\n    \n    try:\n        # Clear existing data\n        print(\"üßπ Clearing existing test data...\")\n        cur.execute(\"TRUNCATE TABLE tasks, plans, users CASCADE\")\n        \n        # Insert users\n        print(\"üë• Inserting users...\")\n        for user in users:\n            cur.execute(\"\"\"\n                INSERT INTO users (id, email, first_name, last_name, display_name, \n                                 job_title, department, timezone, created_at, is_active)\n                VALUES (%(id)s, %(email)s, %(first_name)s, %(last_name)s, %(display_name)s,\n                       %(job_title)s, %(department)s, %(timezone)s, %(created_at)s, %(is_active)s)\n            \"\"\", user)\n        \n        # Insert plans\n        print(\"üìã Inserting plans...\")\n        for plan in plans:\n            cur.execute(\"\"\"\n                INSERT INTO plans (id, title, description, owner_id, created_at, \n                                 due_date, status, priority, tags)\n                VALUES (%(id)s, %(title)s, %(description)s, %(owner_id)s, %(created_at)s,\n                       %(due_date)s, %(status)s, %(priority)s, %(tags)s)\n            \"\"\", plan)\n        \n        # Insert tasks\n        print(\"‚úÖ Inserting tasks...\")\n        for task in tasks:\n            cur.execute(\"\"\"\n                INSERT INTO tasks (id, title, description, plan_id, assignee_id, \n                                 created_at, due_date, status, priority, \n                                 estimated_hours, actual_hours, completion_percentage, labels)\n                VALUES (%(id)s, %(title)s, %(description)s, %(plan_id)s, %(assignee_id)s,\n                       %(created_at)s, %(due_date)s, %(status)s, %(priority)s,\n                       %(estimated_hours)s, %(actual_hours)s, %(completion_percentage)s, %(labels)s)\n            \"\"\", task)\n        \n        conn.commit()\n        print(\"‚úÖ Test data seeding completed successfully!\")\n        \n    except Exception as e:\n        conn.rollback()\n        print(f\"‚ùå Error seeding database: {e}\")\n        raise\n    finally:\n        cur.close()\n        conn.close()\n\nif __name__ == \"__main__\":\n    seed_database()\n```\n\n### Testing Strategy\n\n**Development Environment Testing:**\n- Automated environment setup validation\n- Service health check testing\n- Hot reload functionality testing\n- IDE integration testing\n- Performance baseline testing\n\n**Environment Validation Script:**\n```bash\n#!/bin/bash\n# dev-environment/scripts/validate-environment.sh\n\nset -e\n\necho \"üîç Validating development environment...\"\n\n# Check Docker services\necho \"üìä Checking Docker services...\"\ndocker-compose -f dev-environment/docker/docker-compose.dev.yml ps\n\n# Test database connectivity\necho \"üóÑÔ∏è  Testing database connectivity...\"\npsql \"$DATABASE_URL\" -c \"SELECT version();\" >/dev/null\necho \"‚úÖ Database connection successful\"\n\n# Test Redis connectivity\necho \"üì¶ Testing Redis connectivity...\"\nredis-cli -u \"$REDIS_URL\" ping | grep -q PONG\necho \"‚úÖ Redis connection successful\"\n\n# Test API endpoints\necho \"üåê Testing API endpoints...\"\ncurl -f \"http://localhost:$MCP_SERVER_PORT/health\" >/dev/null\necho \"‚úÖ MCP Server health check passed\"\n\ncurl -f \"http://localhost:$OPENWEBUI_PORT\" >/dev/null\necho \"‚úÖ OpenWebUI accessibility verified\"\n\n# Test hot reload\necho \"üîÑ Testing hot reload...\"\nTEST_FILE=\"planner-mcp-server/test_hot_reload.py\"\necho \"# Hot reload test\" > \"$TEST_FILE\"\nsleep 3\nrm \"$TEST_FILE\"\necho \"‚úÖ Hot reload test completed\"\n\n# Validate IDE configuration\necho \"üõ†Ô∏è  Validating IDE configuration...\"\nif [ -f \".vscode/settings.json\" ]; then\n    echo \"‚úÖ VS Code configuration found\"\nfi\n\necho \"üéâ Environment validation completed successfully!\"\n```\n\n## Change Log\n\n| Date | Version | Description | Author |\n|------|---------|-------------|--------|\n| 2025-10-06 | 1.0 | Initial development environment automation story | BMad Framework |\n\n## Dev Agent Record\n\n*This section will be populated by the development agent during implementation*\n\n### Agent Model Used\n*{{agent_model_name_version}}*\n\n### Debug Log References\n*Reference any debug logs or traces generated during development*\n\n### Completion Notes List\n*Notes about the completion of tasks and any issues encountered*\n\n### File List\n*List all files created, modified, or affected during story implementation*\n\n## QA Results\n\n*Results from QA Agent QA review of the completed story implementation*