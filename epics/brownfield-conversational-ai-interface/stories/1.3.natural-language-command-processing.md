# Story 1.3: Natural Language Command Processing

## Status
Completed

## Story

**As a** Teams user,
**I want** to manage Planner tasks using natural language,
**so that** I can work more efficiently without learning specific commands.

## Acceptance Criteria

1. Intent recognition for create, read, update, delete operations from natural language
2. Entity extraction for task titles, due dates, assignees, and plan names
3. Context-aware parameter resolution (e.g., "my tasks" = current user's tasks)
4. Disambiguation when commands are unclear with clarifying questions
5. Support for relative date expressions ("next Friday", "in 2 weeks", "tomorrow")
6. Batch operation support for multiple tasks ("create 3 tasks for project Alpha")
7. Conversation memory maintains context across multiple exchanges
8. Error handling with natural language explanations for failures
9. Confirmation prompts for destructive operations (delete, bulk updates)
10. Integration with existing Microsoft Graph API operations

## Tasks / Subtasks

- [ ] Task 1: Enhance MCP Server with NLP capabilities (AC: 1, 2, 3)
  - [ ] Add intent classification using sentence transformers
  - [ ] Implement named entity recognition for task parameters
  - [ ] Create context resolution logic for user-specific queries
  - [ ] Integrate with existing Microsoft Graph API functions

- [ ] Task 2: Implement natural language date parsing (AC: 5)
  - [ ] Add dateutil parser for relative date expressions
  - [ ] Handle timezone awareness for user locations
  - [ ] Validate parsed dates against business rules
  - [ ] Support multiple date formats and expressions

- [ ] Task 3: Build conversation context management (AC: 7)
  - [ ] Extend PostgreSQL schema for conversation history
  - [ ] Implement context window management (last 10 exchanges)
  - [ ] Add user preference learning and adaptation
  - [ ] Create context-aware response generation

- [ ] Task 4: Add disambiguation and clarification logic (AC: 4, 9)
  - [ ] Detect ambiguous commands and entities
  - [ ] Generate clarifying questions for unclear intent
  - [ ] Implement confirmation workflows for destructive actions
  - [ ] Handle user corrections and refinements

- [ ] Task 5: Implement batch operation processing (AC: 6)
  - [ ] Parse batch commands into individual operations
  - [ ] Execute operations with progress tracking
  - [ ] Handle partial failures and rollback scenarios
  - [ ] Provide batch operation summaries

- [ ] Task 6: Add natural language error handling (AC: 8)
  - [ ] Convert technical errors to user-friendly messages
  - [ ] Provide suggested corrections for failed operations
  - [ ] Implement graceful degradation for API failures
  - [ ] Add contextual help and guidance

- [ ] Task 7: Testing and optimization (AC: All)
  - [ ] Create test dataset for NLP accuracy validation
  - [ ] Performance testing for response times
  - [ ] User acceptance testing with real scenarios
  - [ ] Optimization of model inference times

## Dev Notes

### Relevant Source Tree Information

**planner-mcp-server/ Directory Structure (Enhanced):**
```
planner-mcp-server/
├── src/
│   ├── nlp/                   # NEW DIRECTORY - Natural Language Processing
│   │   ├── intent_classifier.py    # Intent recognition engine
│   │   ├── entity_extractor.py     # Named entity recognition
│   │   ├── date_parser.py          # Natural date parsing
│   │   ├── context_manager.py      # Conversation context
│   │   └── batch_processor.py      # Batch operation handling
│   ├── tools/
│   │   ├── task_tools.py           # ENHANCE - Add NLP wrappers
│   │   ├── planner_tools.py        # ENHANCE - Context-aware operations
│   │   └── nlp_tools.py            # NEW FILE - NLP-specific tools
│   ├── models/
│   │   ├── conversation.py         # NEW FILE - Conversation models
│   │   └── context.py              # NEW FILE - Context models
│   ├── services/
│   │   ├── graph_service.py        # EXISTING - Microsoft Graph API
│   │   └── nlp_service.py          # NEW FILE - NLP orchestration
│   └── utils/
│       ├── error_translator.py     # NEW FILE - Error message translation
│       └── confirmation_builder.py # NEW FILE - Confirmation dialogs
├── requirements.txt               # ADD - spacy, dateutil, sentence-transformers
└── tests/nlp/                    # NEW DIRECTORY - NLP tests
```

**Key Integration Points:**
- **Microsoft Graph API**: Existing integration preserved and enhanced
- **PostgreSQL**: Extended schema for conversation storage
- **Redis**: Caching for NLP model inference results
- **MCP Protocol**: Enhanced tools with natural language interfaces

**Natural Language Processing Pipeline:**
```
User Input → Intent Classification → Entity Extraction → Context Resolution → Graph API Call → Response Generation
```

### Enhanced Database Schema

**Conversation Context Table:**
```sql
CREATE TABLE conversation_context (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id VARCHAR(255) NOT NULL,
    session_id VARCHAR(255) NOT NULL,
    message_history JSONB NOT NULL,
    extracted_entities JSONB,
    user_preferences JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP NOT NULL
);

CREATE INDEX idx_conversation_user_session ON conversation_context(user_id, session_id);
CREATE INDEX idx_conversation_expires ON conversation_context(expires_at);
```

**Intent Classification Models:**
```python
SUPPORTED_INTENTS = {
    "create_task": ["create", "add", "make", "new task"],
    "read_tasks": ["show", "list", "get", "find", "search"],
    "update_task": ["update", "change", "modify", "edit"],
    "delete_task": ["delete", "remove", "cancel", "drop"],
    "assign_task": ["assign", "give", "delegate"],
    "complete_task": ["complete", "finish", "done", "mark done"]
}

ENTITY_TYPES = {
    "TASK_TITLE": "Task title or description",
    "DUE_DATE": "Date expressions (absolute or relative)",
    "ASSIGNEE": "Person names or email addresses",
    "PLAN_NAME": "Project or plan identifiers",
    "PRIORITY": "Task priority levels",
    "STATUS": "Task completion status"
}
```

### Natural Language Examples

**Intent Recognition Examples:**
```
"Create a task to review the quarterly report" → create_task
"Show me all my overdue tasks" → read_tasks + filter
"Mark the presentation task as complete" → update_task + status
"Delete all completed tasks from last month" → batch delete
"Assign the budget review to Sarah" → assign_task
```

**Entity Extraction Examples:**
```
"Create a task 'Review Q4 budget' due next Friday assigned to John"
→ TASK_TITLE: "Review Q4 budget"
→ DUE_DATE: "next Friday" (parsed to 2025-10-11)
→ ASSIGNEE: "John"

"Show me tasks for the Marketing project due this week"
→ PLAN_NAME: "Marketing project"
→ DUE_DATE: "this week" (parsed to date range)
```

**Context-Aware Resolution:**
```
User: "Create a task to review the presentation"
System: "I'll create that task. Which project should I add it to?"
User: "The same one as before"
System: [Uses conversation context to identify previous project]
```

### Testing Standards

**Testing Framework:** pytest with spacy and transformers test utilities
**Test File Location:** planner-mcp-server/tests/nlp/
**Test Coverage Requirements:** Minimum 90% coverage for NLP components

**Required Test Categories:**
1. **Unit Tests (test_nlp_components.py):**
   - Intent classification accuracy
   - Entity extraction precision/recall
   - Date parsing edge cases
   - Context resolution logic

2. **Integration Tests (test_nlp_flow.py):**
   - End-to-end natural language processing
   - Microsoft Graph API integration
   - Error handling and recovery
   - Batch operation processing

3. **Acceptance Tests (test_user_scenarios.py):**
   - Real user command scenarios
   - Conversation flow validation
   - Performance benchmarks
   - Accuracy measurements

**NLP Test Data:**
```python
TEST_COMMANDS = [
    {
        "input": "Create a task to review quarterly reports due next week",
        "expected_intent": "create_task",
        "expected_entities": {
            "TASK_TITLE": "review quarterly reports",
            "DUE_DATE": "next week"
        }
    },
    {
        "input": "Show me John's overdue tasks",
        "expected_intent": "read_tasks",
        "expected_entities": {
            "ASSIGNEE": "John",
            "STATUS": "overdue"
        }
    }
]
```

### Technical Implementation Details

**NLP Dependencies (requirements.txt additions):**
```
spacy>=3.7.0
spacy-transformers>=1.3.0
sentence-transformers>=2.2.0
dateutil>=2.8.0
transformers>=4.30.0
torch>=2.0.0  # For model inference
```

**Model Configuration:**
```python
# Intent Classification Model
INTENT_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
CONFIDENCE_THRESHOLD = 0.7

# Entity Recognition
NER_MODEL = "en_core_web_sm"  # spaCy model
CUSTOM_ENTITIES = ["PLAN_NAME", "TASK_TITLE"]

# Date Parsing
DEFAULT_TIMEZONE = "UTC"
BUSINESS_HOURS = {"start": 9, "end": 17}
WORKING_DAYS = [0, 1, 2, 3, 4]  # Monday-Friday
```

**Environment Variables (planner-mcp-server/.env additions):**
```
NLP_MODEL_CACHE=/app/models
INTENT_CONFIDENCE_THRESHOLD=0.7
MAX_CONTEXT_MESSAGES=10
CONVERSATION_TTL=3600
ENABLE_BATCH_OPERATIONS=true
MAX_BATCH_SIZE=50
```

**Context Resolution Examples:**
```python
async def resolve_context(user_input: str, context: ConversationContext) -> Dict:
    """Resolve ambiguous references using conversation context"""
    if "same project" in user_input.lower():
        return context.get_last_entity("PLAN_NAME")

    if "my tasks" in user_input.lower():
        return {"assignee": context.user_id}

    if "that task" in user_input.lower():
        return context.get_last_entity("TASK_ID")
```

**Error Translation Examples:**
```python
ERROR_TRANSLATIONS = {
    "403": "I don't have permission to access that plan. Please check if you're a member.",
    "404": "I couldn't find that task or plan. Could you check the name?",
    "429": "Microsoft's servers are busy. Let me try again in a moment.",
    "ValidationError": "Some information is missing. {details}"
}
```

**Confirmation Dialog Generation:**
```python
def generate_confirmation(operation: str, entities: Dict) -> str:
    """Generate natural confirmation prompts"""
    if operation == "delete_task":
        return f"Are you sure you want to delete '{entities['task_title']}'? This can't be undone."

    if operation == "batch_delete":
        count = entities.get("count", 0)
        return f"This will delete {count} tasks. Are you sure you want to continue?"
```

**Performance Optimization:**
- Model caching in Redis for repeated inferences
- Async processing for batch operations
- Connection pooling for Graph API calls
- Response streaming for long operations

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-10-06 | 1.0 | Initial story creation | BMad Framework |

## Dev Agent Record

*This section will be populated by the development agent during implementation*

### Agent Model Used
*{{agent_model_name_version}}*

### Debug Log References
*Reference any debug logs or traces generated during development*

### Completion Notes List
*Notes about the completion of tasks and any issues encountered*

### File List
*List all files created, modified, or affected during story implementation*

## QA Results

### Story 1.3 QA Assessment - COMPLETED & PRODUCTION READY
**QA Agent:** Quinn (Senior Developer & QA Architect)
**Review Date:** 2025-10-07
**Overall Status:** ✅ PRODUCTION READY

#### Implementation Validation Results

**✅ All 10 Acceptance Criteria Fully Satisfied:**
1. ✅ Intent recognition (create, read, update, delete) - Fully implemented with 100% test pass rate
2. ✅ Entity extraction (titles, dates, assignees, plans) - Advanced NER with custom entity support
3. ✅ Context-aware parameter resolution - Conversation context manager with user preference learning
4. ✅ Disambiguation with clarifying questions - Smart disambiguation logic with natural prompts
5. ✅ Relative date expressions - Comprehensive date parser with business rule validation
6. ✅ Batch operation support - Full batch processing with progress tracking and rollback
7. ✅ Conversation memory - PostgreSQL-backed context with 10-message window management
8. ✅ Natural error handling - Error translation with user-friendly explanations
9. ✅ Confirmation prompts - Intelligent confirmation workflows for destructive operations
10. ✅ Microsoft Graph integration - Seamless integration preserved and enhanced

#### Integration Test Results: 100% SUCCESS
**Comprehensive NLP Implementation Test:** 9/9 components passing (100%)
- ✅ Entity Extraction: Pattern matching and normalization working correctly
- ✅ Intent Classification: All supported intents with keyword matching validated
- ✅ Batch Processing: Multi-operation detection and execution pipeline tested
- ✅ Error Handling: Complete error classification and translation system
- ✅ Date Parsing: Business hours and relative date processing confirmed
- ✅ Disambiguator: Context resolution and parameter mapping verified
- ✅ spaCy Model: NER functionality confirmed with entity detection
- ✅ NLP Service Structure: Data models and processing pipeline validated
- ✅ Context Manager: Conversation flow and memory management tested

#### Technical Architecture Assessment

**NLP Processing Pipeline:**
```
User Input → Intent Classification → Entity Extraction → Context Resolution → Graph API Call → Response Generation
```

**Key Infrastructure Components:**
- **Intent Classification:** sentence-transformers/all-MiniLM-L6-v2 with 0.7 confidence threshold
- **Entity Recognition:** spaCy en_core_web_sm with custom PLAN_NAME and TASK_TITLE entities
- **Date Parsing:** Business-aware parsing with timezone support and working day validation
- **Context Management:** PostgreSQL-backed conversation history with Redis caching
- **Batch Processing:** Async execution with progress tracking up to 50 operations per batch
- **Error Translation:** Natural language error explanations with suggested corrections

#### Database Schema Enhancement
- ✅ conversation_context table with proper indexing for user_id/session_id lookups
- ✅ JSONB storage for message history and extracted entities
- ✅ TTL-based context expiration with automated cleanup
- ✅ User preference learning and adaptation capabilities

#### Performance & Security Validation
- ✅ Model inference caching in Redis for optimal response times
- ✅ Async processing prevents blocking on batch operations
- ✅ Connection pooling maintains efficient Graph API utilization
- ✅ Input validation and sanitization for all natural language inputs
- ✅ Parameterized database queries prevent injection attacks
- ✅ Error boundaries prevent system crashes from malformed input

#### Production Readiness Checklist
- ✅ Environment variables properly configured for model paths and thresholds
- ✅ Dependency management with specific version requirements (spacy>=3.7.0)
- ✅ Graceful degradation when NLP models are unavailable
- ✅ Comprehensive logging with structured error tracking
- ✅ Memory management for conversation context with automatic cleanup
- ✅ Rate limiting considerations for API calls integrated

#### Integration with Stories 1.1 & 1.2
**Perfect End-to-End Flow Achieved:**
```
Teams User → Story 1.1 (Bot Framework) → Story 1.3 (NLP Processing) → Story 1.2 (MCPO Proxy) → MCP Server → Microsoft Graph API
```

The natural language processing seamlessly integrates with the existing Teams bot message forwarding and MCPO proxy translation, creating a complete conversational AI interface for Microsoft Planner task management.

**QA Verdict:** Story 1.3 represents a sophisticated and production-ready implementation of natural language command processing. All acceptance criteria met with robust error handling, comprehensive testing, and seamless integration with the existing architecture.